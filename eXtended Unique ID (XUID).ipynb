{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard UUIDs are nice and all, but why not extend the character range to include all standard ascii letters and numbers, also, get rid of embedded MAC addresses and time stamps.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naSJps4K-61Q6-n94H-ynvg-nNzMUQ30BvUT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0x7941567531766d7477496c55573855434e51465165584372554c755a6165334e'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from secrets import token_urlsafe as TUS\n",
    "\n",
    "class xuid:\n",
    "    def __init__(self, TUS_length=64):\n",
    "        initial_string = TUS(TUS_length).replace(\"_\", \"\").replace(\"-\", \"\")\n",
    "        self.used_chars = initial_string[:32]\n",
    "        segments = (initial_string[0:8],\n",
    "                    initial_string[8:12],\n",
    "                    initial_string[12:16],\n",
    "                    initial_string[16:20],\n",
    "                    initial_string[20:32])\n",
    "        self.xuid_join = \"-\".join(segments)\n",
    "    def __str__(self):\n",
    "        return(self.xuid_join)\n",
    "    def __int__(self):\n",
    "        return(self.short_interizer())\n",
    "    def __index__(self):\n",
    "        return(self.short_interizer())\n",
    "    def long_interizer(self):\n",
    "        charlist = list(self.used_chars)\n",
    "        ordlist = [ord(x) for x in charlist]\n",
    "        binlist = [bin(x) for x in ordlist]\n",
    "        strbin = [str(x)[2:] for x in binlist]\n",
    "        strbin8 = [f\"{'0' * (8-len(x))}{x}\" for x in strbin]\n",
    "        bstr = \"0b\" + \"\".join(strbin8)\n",
    "        return(int(bstr, 2))\n",
    "    def short_interizer(self):\n",
    "        strlist = [str(bin(ord(x)))[2:] for x in list(self.used_chars)]\n",
    "        return(int(\"0b\" +  \"\".join([f\"{'0' * (8-len(x))}{x}\" for x in strlist]), 2))\n",
    "        \n",
    "    \n",
    "print(str(xuid()))\n",
    "int(xuid())\n",
    "hex(xuid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object is very simple, just a random string from `token_urlsafe`, and then sliced up to a format we can use.\n",
    "Now let's figure out which method of creating the __int__ is faster, with a lot of variables or our two list comprehensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Time:   494.6031452s\n",
      "Long Time:    555.9972513s\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "def sf():\n",
    "    xuid().short_interizer()\n",
    "def lf():\n",
    "    xuid().long_interizer()\n",
    "st = timeit.timeit(lambda: sf(), number=10000000)\n",
    "lt = timeit.timeit(lambda: lf(), number=10000000)\n",
    "print(f\"Short Time:   {st}s\\nLong Time:    {lt}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we can see that the short interizer is the faster method. As this is just a random series of characters, there's no reason to reinstantiate an older xuid. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
