{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard UUIDs are nice and all, but why not extend the character range to include all standard ascii letters and numbers, also, get rid of embedded MAC addresses and time stamps.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x8SpJpyQ-3Cmd-9og1-Lea5-HjmYLChkR2IF\n",
      "fUTdIytT-IgW2-BoPt-VxN1-MXtJH8gJrgLj\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0x434175754f4e356b326c74565a6e666d6e496d333043677450324b596a676c6a'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from secrets import token_urlsafe as TUS\n",
    "\n",
    "class xuid:\n",
    "    def __init__(self, TUS_length=64):\n",
    "        \"\"\"Initializes a string using secrets.token_urlsafe, this string is\n",
    "            split into sections to imitate a uuid.\n",
    "\n",
    "            Upon initialization it creates some of the same standard outputs\n",
    "                as uuid, including urn (urn:xuid:{xuid}) and fields (tuple of\n",
    "                values). \n",
    "\n",
    "        Args:\n",
    "            TUS_length (int, optional): An int that is used in the \n",
    "                secrets.token_urlsafe (TUS) function to generate the random \n",
    "                string of characters. Defaults to 64. \n",
    "        \"\"\"\n",
    "        if TUS_length <= 0:\n",
    "            raise ValueError(\"TUS_length cannot be less than or equal to 0. \"\n",
    "                             \"An integer greater than or equal to 30 is \"\n",
    "                             \"recommended, default is 64.\")\n",
    "        initial_string = TUS(TUS_length).replace(\"_\", \"\").replace(\"-\", \"\")\n",
    "        while len(initial_string) <= 32:\n",
    "            initial_string += TUS(TUS_length).replace(\"_\", \"\").replace(\"-\", \"\")\n",
    "        self.used_chars = initial_string[:32]\n",
    "        segments = (initial_string[0:8],\n",
    "                    initial_string[8:12],\n",
    "                    initial_string[12:16],\n",
    "                    initial_string[16:20],\n",
    "                    initial_string[20:32])\n",
    "        self.xuid_join = \"-\".join(segments)\n",
    "        self.fields = segments\n",
    "        self.urn = f\"urn:xuid:{self.xuid_join}\"\n",
    "    def __str__(self):\n",
    "        \"\"\"Returns a simple 36 character string in the same style as UUID\n",
    "        \"\"\"\n",
    "        return(self.xuid_join)\n",
    "    def __int__(self):\n",
    "        \"\"\"Returns an integer generated from the UTF-8 ordinal values of the \n",
    "            initial random string. \n",
    "        \"\"\"\n",
    "        return(self.shoint())\n",
    "    def __index__(self):\n",
    "        \"\"\"Enables the return of hex and byte values using an integer generated \n",
    "            from the UTF-8 ordinal values of the initial random string.  \n",
    "        \"\"\"\n",
    "        return(self.shoint())\n",
    "    def __repr__(self):\n",
    "        return(f\"XUID('{self.xuid_join}')\")\n",
    "    def long_interizer(self):\n",
    "        \"\"\"A step by step approach to creating an integer from the randomly \n",
    "            generated string of letters from secrets.token_urlsafe.\n",
    "            Steps:\n",
    "            1. Convert string to list of chars\n",
    "            2. Create list of ordinal values from list of chars\n",
    "            3. Create list of binary from ordinal values\n",
    "            4. Create list of strings from binary values\n",
    "            5. Correct list of binary strings to meet 8-bits per binary string.\n",
    "            6. Concatenate binary strings into longer binary string suitable\n",
    "                for conversion using int() built in.\n",
    "            7. Return int(long binary string)\n",
    "        \"\"\"\n",
    "        charlist = list(self.used_chars)\n",
    "        ordlist = [ord(x) for x in charlist]\n",
    "        binlist = [bin(x) for x in ordlist]\n",
    "        strbin = [str(x)[2:] for x in binlist]\n",
    "        strbin8 = [f\"{'0' * (8-len(x))}{x}\" for x in strbin]\n",
    "        bstr = \"0b\" + \"\".join(strbin8)\n",
    "        return(int(bstr, 2))\n",
    "    def short_interizer(self):\n",
    "        \"\"\"A short version of long_interizer() using list comprehension better.\n",
    "\n",
    "            See the documentation for long_interizer for the steps to create \n",
    "                the integer.  \n",
    "\n",
    "            Testing shows this is a faster method than long_interizer()\n",
    "        \"\"\"\n",
    "        strlist = [str(bin(ord(x)))[2:] for x in list(self.used_chars)]\n",
    "        return(int(\"0b\" +  \"\".join(\n",
    "                [f\"{'0' * (8-len(x))}{x}\" for x in strlist]), 2))\n",
    "    def shoint(self):\n",
    "        \"\"\"An even shorter version of long_interizer() using list comprehension.\n",
    "        \n",
    "            See the documentation for long_interizer for the steps to create\n",
    "                the integer.\n",
    "                \n",
    "            Testing shows this is a faster method than short_interizer()\"\"\"\n",
    "        return(\n",
    "            int(\"0b\" +  \"\".join(\n",
    "                [f\"{'0'*8}{str(bin(ord(x)))[2:]}\"[-8:] for x in list(self.used_chars)]\n",
    "                               ), 2\n",
    "            ))\n",
    "        \n",
    "    \n",
    "print(str(xuid()))\n",
    "print(xuid())\n",
    "int(xuid())\n",
    "hex(xuid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object is very simple, just a random string from `token_urlsafe`, and then sliced up to a format we can use.\n",
    "Now let's figure out which method of creating the __int__ is faster, with a lot of variables or our two list comprehensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Time:   171.2818116s\n",
      "Long Time:    190.40002690000003s\n",
      "Short time is 11.16% faster\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "def sf():\n",
    "    xuid().short_interizer()\n",
    "def lf():\n",
    "    xuid().long_interizer()\n",
    "st = timeit.timeit(lambda: sf(), number=1000*100*100)\n",
    "lt = timeit.timeit(lambda: lf(), number=1000*100*100)\n",
    "print(f\"Short Time:   {st}s\\nLong Time:    {lt}s\")\n",
    "print(f\"Short time is {(lt/st)*100 - 100:2.2f}% faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we can see that the short interizer is the faster method. As this is just a random series of characters, there's no reason to reinstantiate an older xuid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Update 2022-06-02***  \n",
    "I did some more \"optimization\" and created an even faster method of generating the integer that could be a single line if I had ignored the PEP8 rule of 79 chars per line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shoint Time: 162.60144479999997\n",
      "Shoint is 17.10% faster than long interizer\n",
      "Shoint is 5.34% faster than short interizer\n"
     ]
    }
   ],
   "source": [
    "def s():\n",
    "    xuid().shoint()\n",
    "sht = timeit.timeit(lambda: s(), number=1000*100*100)\n",
    "print(f\"Shoint Time: {sht}\")\n",
    "print(f\"Shoint is {(lt/sht)*100 - 100:2.2f}% faster than long interizer\")\n",
    "print(f\"Shoint is {(st/sht)*100 - 100:2.2f}% faster than short interizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also laying the groundwork to test for XUID collisions by generating a ton of them, and then checking for duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import string, os, glob\n",
    "\n",
    "def dictinit():\n",
    "    d = {}\n",
    "    for char1 in list(string.ascii_letters + string.digits):\n",
    "        for char2 in list(string.ascii_letters + string.digits):\n",
    "            d[char1 + char2] = []\n",
    "    return(d)\n",
    "\n",
    "def test_write(testing_dir, d):\n",
    "    for char in d.keys():\n",
    "        with open(f\"{testing_dir}{os.sep}{char}.txt\", \"a\") as f:\n",
    "            for x in d[char]:\n",
    "                f.write(f\"{x}\\n\".encode(\"ascii\"))\n",
    "\n",
    "def check_file(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        L = f.split(\"\\n\")\n",
    "    L = [x for x in L if len(x) == 36]\n",
    "    S = list(set(L))\n",
    "    if len(L) != len(S):\n",
    "        print(f\"{filepath} includes {len(L)-len(S)} collisions!\")\n",
    "    else:\n",
    "        print(\"No collisions found.\")\n",
    "        \n",
    "def collision_test(testing_dir, test_count=10_000_000_000, index_pause=10_000_000):\n",
    "    for i in range(test_count):\n",
    "        if i == 0:\n",
    "            d = dictinit()\n",
    "        if i % index_pause == 0 and i > 0:\n",
    "            print(f\"{i//1_000_000:^5}M - {i/test_count:>6}%\")\n",
    "            test_write(testing_dir, d)\n",
    "            del d # hashtag memory management\n",
    "            d = dictinit()\n",
    "        x = str(xuid())\n",
    "        d[x[:2]].append(x)\n",
    "    for f in glob.glob(f\"{testing_dir}{os.sep}*.txt\"):\n",
    "        check_file()\n",
    "#testdir = r\"\"\n",
    "#collision_test(testdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
